{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from src.utils import load_prompt\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "load_dotenv(\"src/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def load_text(path):\n",
    "    with open(path, \"r\") as fp:\n",
    "        return fp.read()\n",
    "\n",
    "def load_prompt(prompt):\n",
    "    return load_text(f\"prompts/{prompt}.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onboarding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding_prompt = load_prompt(\"onboarding\")\n",
    "human_prompt_template = \"{technology_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_prompt = SystemMessagePromptTemplate.from_template(onboarding_prompt)\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_prompt_template)\n",
    "\n",
    "onboarding_chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding = chat(\n",
    "    onboarding_chat_prompt.format_prompt(\n",
    "        technology_name=\"Apache Beam\"\n",
    "    ).to_messages()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Onboarding\n",
       "\n",
       "### What problem does this aim to solve?\n",
       "\n",
       "Apache Beam addresses the challenge of building and executing data processing pipelines that are scalable, portable, and expressive. In the world of big data, processing large volumes of data efficiently and reliably is a complex task. Traditional approaches often involve writing custom code for each data processing job, leading to code duplication, maintenance challenges, and limited scalability. Apache Beam solves these problems by providing a unified programming model and a set of APIs that enable developers to write data processing pipelines that can run on various execution engines, such as Apache Flink, Apache Spark, and Google Cloud Dataflow.\n",
       "\n",
       "### What sub-category of technologies is this?\n",
       "\n",
       "Apache Beam falls under the sub-category of \"data processing frameworks\" within the broader field of big data and distributed computing. It is a tool that simplifies the development and execution of data processing pipelines, allowing developers to focus on the logic of their data transformations rather than the underlying infrastructure. Apache Beam's portable and expressive nature makes it suitable for a wide range of use cases, including batch and stream processing, ETL (Extract, Transform, Load) pipelines, and real-time analytics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(onboarding.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Developer life with/without the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Developer life with/without this tool\n",
       "\n",
       "### Without Kubernetes\n",
       "\n",
       "#### Manual Deployment and Scaling\n",
       "\n",
       "Developers are responsible for manually deploying and scaling applications on individual servers or virtual machines.\n",
       "This process involves configuring and managing each server individually, which can be time-consuming and error-prone.\n",
       "\n",
       "#### Resource Management\n",
       "\n",
       "Without Kubernetes, developers need to manually allocate and manage resources for each application.\n",
       "This includes monitoring resource usage, optimizing resource allocation, and ensuring efficient utilization.\n",
       "\n",
       "#### High Availability and Fault Tolerance\n",
       "\n",
       "Ensuring high availability and fault tolerance requires manual setup and configuration of load balancers, failover mechanisms, and redundancy.\n",
       "This can be complex and time-consuming, especially in large-scale deployments.\n",
       "\n",
       "#### Example Scenario\n",
       "\n",
       "A developer needs to deploy a microservices-based application on multiple servers, manage resource allocation, and ensure high availability.\n",
       "This involves manually configuring load balancers, monitoring resource usage, and handling failover scenarios.\n",
       "\n",
       "### With Kubernetes\n",
       "\n",
       "#### Automated Deployment and Scaling\n",
       "\n",
       "Kubernetes automates the deployment and scaling of applications using containerization.\n",
       "Developers define the desired state of the application using YAML or JSON files, and Kubernetes takes care of the rest.\n",
       "\n",
       "Example Deployment YAML:\n",
       "\n",
       "```yaml\n",
       "apiVersion: apps/v1\n",
       "kind: Deployment\n",
       "metadata:\n",
       "  name: my-app\n",
       "spec:\n",
       "  replicas: 3\n",
       "  selector:\n",
       "    matchLabels:\n",
       "      app: my-app\n",
       "  template:\n",
       "    metadata:\n",
       "      labels:\n",
       "        app: my-app\n",
       "    spec:\n",
       "      containers:\n",
       "      - name: my-app\n",
       "        image: my-app:latest\n",
       "        ports:\n",
       "        - containerPort: 8080\n",
       "```\n",
       "\n",
       "#### Efficient Resource Management\n",
       "\n",
       "Kubernetes automatically manages resource allocation based on the defined requirements and constraints.\n",
       "It optimizes resource utilization by dynamically scaling resources up or down based on demand.\n",
       "\n",
       "#### High Availability and Fault Tolerance\n",
       "\n",
       "Kubernetes provides built-in mechanisms for high availability and fault tolerance.\n",
       "It automatically handles load balancing, failover, and replication of application instances across multiple nodes.\n",
       "\n",
       "#### Example Workflow\n",
       "\n",
       "A developer defines the desired state of the application using a Kubernetes deployment file (`kubectl apply -f deployment.yaml`).\n",
       "Kubernetes automatically deploys the application, manages resource allocation, and ensures high availability.\n",
       "Scaling the application can be done by updating the deployment file (`kubectl apply -f deployment.yaml`) or using commands like `kubectl scale`.\n",
       "\n",
       "Overall, Kubernetes simplifies the deployment, scaling, resource management, and high availability of applications, allowing developers to focus on writing code rather than managing infrastructure."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with_and_without_prompt = load_prompt(\"with-and-without\")\n",
    "human_prompt_template = \"{technology_name}\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(with_and_without_prompt)\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_prompt_template)\n",
    "\n",
    "with_and_without_chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt]\n",
    ")\n",
    "\n",
    "with_and_without = chat(\n",
    "    with_and_without_chat_prompt.format_prompt(\n",
    "        technology_name=\"Kubernetes\"\n",
    "    ).to_messages()\n",
    ")\n",
    "\n",
    "\n",
    "display(Markdown(with_and_without.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Core Concepts\n",
       "\n",
       "### Data Processing Pipelines\n",
       "Apache Beam is a technology that enables the development and execution of data processing pipelines. A data processing pipeline is a sequence of steps that transform and analyze data. It allows you to define the flow of data from source to destination, applying various operations and transformations along the way.\n",
       "\n",
       "### Unified Programming Model\n",
       "Apache Beam provides a unified programming model that allows you to write data processing pipelines in a language-agnostic manner. This means that you can write your pipelines using one of the supported programming languages (such as Java, Python, or Go) and execute them on different execution engines (such as Apache Flink, Apache Spark, or Google Cloud Dataflow) without modifying the code.\n",
       "\n",
       "### PCollection\n",
       "In Apache Beam, a PCollection (short for \"processing collection\") represents a collection of data elements that are processed as part of a pipeline. It can be thought of as an abstraction for a distributed data set. PCollections can be created from various data sources, such as files, databases, or message queues, and can be transformed using operations like filtering, mapping, or aggregating.\n",
       "\n",
       "### Transformations\n",
       "Transformations are the building blocks of Apache Beam pipelines. They define the operations that are applied to PCollections to produce new PCollections. Transformations can be simple, such as filtering or mapping individual elements, or they can be complex, involving aggregations or joining multiple PCollections together. Apache Beam provides a rich set of built-in transformations, and you can also create custom transformations to suit your specific needs.\n",
       "\n",
       "### Windowing\n",
       "Windowing is a concept in Apache Beam that allows you to divide the data in a PCollection into logical windows based on time or other criteria. This is useful when dealing with streaming data or when you want to perform computations over fixed time intervals or sliding windows. Windowing enables you to apply operations like aggregations or sessionization on data within each window, providing more flexibility in data processing."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "core_concepts_prompt = load_prompt(\"core-concepts\")\n",
    "human_prompt_template = \"{technology_name}\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(core_concepts_prompt)\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_prompt_template)\n",
    "\n",
    "core_concepts_chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt]\n",
    ")\n",
    "\n",
    "core_concepts = chat(\n",
    "    core_concepts_chat_prompt.format_prompt(\n",
    "        technology_name=\"Apache Beam\"\n",
    "    ).to_messages()\n",
    ")\n",
    "\n",
    "\n",
    "display(Markdown(core_concepts.content))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Core APIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Core APIs\n",
       "\n",
       "### `kubectl create`\n",
       "\n",
       "- Purpose: Creates a resource in the Kubernetes cluster.\n",
       "- Usage Example:\n",
       "\n",
       "```bash\n",
       "kubectl create deployment my-app --image=my-image:latest\n",
       "```\n",
       "\n",
       "### `kubectl apply`\n",
       "\n",
       "- Purpose: Applies a configuration to the Kubernetes cluster, creating or updating resources.\n",
       "- Usage Example:\n",
       "\n",
       "```bash\n",
       "kubectl apply -f my-config.yaml\n",
       "```\n",
       "\n",
       "### `kubectl get`\n",
       "\n",
       "- Purpose: Retrieves information about resources in the Kubernetes cluster.\n",
       "- Usage Example:\n",
       "\n",
       "```bash\n",
       "kubectl get pods\n",
       "```\n",
       "\n",
       "### `kubectl describe`\n",
       "\n",
       "- Purpose: Provides detailed information about a specific resource in the Kubernetes cluster.\n",
       "- Usage Example:\n",
       "\n",
       "```bash\n",
       "kubectl describe pod my-pod\n",
       "```\n",
       "\n",
       "### `kubectl delete`\n",
       "\n",
       "- Purpose: Deletes a resource from the Kubernetes cluster.\n",
       "- Usage Example:\n",
       "\n",
       "```bash\n",
       "kubectl delete deployment my-app\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "core_apis_prompt = load_prompt(\"core-apis\")\n",
    "human_prompt_template = \"{technology_name}\"\n",
    "\n",
    "system_message_prompt = SystemMessagePromptTemplate.from_template(core_apis_prompt)\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_prompt_template)\n",
    "\n",
    "core_apis_chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt]\n",
    ")\n",
    "\n",
    "core_apis = chat(\n",
    "    core_apis_chat_prompt.format_prompt(\n",
    "        technology_name=\"Kubernetes\"\n",
    "    ).to_messages()\n",
    ")\n",
    "\n",
    "\n",
    "display(Markdown(core_apis.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Core APIs\n",
      "\n",
      "### `kubectl create`\n",
      "\n",
      "- Purpose: Creates a resource in the Kubernetes cluster.\n",
      "- Usage Example:\n",
      "\n",
      "```bash\n",
      "kubectl create deployment my-app --image=my-image:latest\n",
      "```\n",
      "\n",
      "### `kubectl apply`\n",
      "\n",
      "- Purpose: Applies a configuration to the Kubernetes cluster, creating or updating resources.\n",
      "- Usage Example:\n",
      "\n",
      "```bash\n",
      "kubectl apply -f my-config.yaml\n",
      "```\n",
      "\n",
      "### `kubectl get`\n",
      "\n",
      "- Purpose: Retrieves information about resources in the Kubernetes cluster.\n",
      "- Usage Example:\n",
      "\n",
      "```bash\n",
      "kubectl get pods\n",
      "```\n",
      "\n",
      "### `kubectl describe`\n",
      "\n",
      "- Purpose: Provides detailed information about a specific resource in the Kubernetes cluster.\n",
      "- Usage Example:\n",
      "\n",
      "```bash\n",
      "kubectl describe pod my-pod\n",
      "```\n",
      "\n",
      "### `kubectl delete`\n",
      "\n",
      "- Purpose: Deletes a resource from the Kubernetes cluster.\n",
      "- Usage Example:\n",
      "\n",
      "```bash\n",
      "kubectl delete deployment my-app\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(core_apis.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real Life Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from tavily import TavilyClient\n",
    "\n",
    "# Initialize clients with API keys\n",
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# assistant_prompt_instruction = \"\"\"You are a basketball expert. \n",
    "# Your goal is to provide answers based on information from the internet. \n",
    "\n",
    "\n",
    "# Real Life Examples\n",
    "# Purpose: Present actual projects or applications that effectively implement the technology, enriching their understanding through practical examples.\n",
    "# Selecting Examples: Choose 2-3 notable real-world projects or applications, ideally from platforms like GitHub.\n",
    "# Brief Descriptions: Provide concise descriptions of each example, focusing on the specific use of the technology.\n",
    "# Direct Links: Include links to the projects or applications for direct access and exploration.\n",
    "\n",
    "# You must use the provided Tavily search API function to find relevant online information. \n",
    "# You should never use your own knowledge to answer questions.\n",
    "# Please include relevant url sources in the end of your answers.\n",
    "# \"\"\"\n",
    "\n",
    "assistant_prompt_instruction=load_prompt(\"real-life-examples\")\n",
    "\n",
    "# Function to perform a Tavily search\n",
    "def tavily_search(query):\n",
    "    search_result = tavily_client.get_search_context(query, search_depth=\"advanced\", max_tokens=8000, include_domains=[\"github.com\"])\n",
    "    return search_result\n",
    "\n",
    "# Function to wait for a run to complete\n",
    "def wait_for_run_completion(thread_id, run_id):\n",
    "    while True:\n",
    "        time.sleep(1)\n",
    "        run = client.beta.threads.runs.retrieve(thread_id=thread_id, run_id=run_id)\n",
    "        print(f\"Current run status: {run.status}\")\n",
    "        if run.status in ['completed', 'failed', 'requires_action']:\n",
    "            return run\n",
    "\n",
    "# Function to handle tool output submission\n",
    "def submit_tool_outputs(thread_id, run_id, tools_to_call):\n",
    "    tool_output_array = []\n",
    "    for tool in tools_to_call:\n",
    "        output = None\n",
    "        tool_call_id = tool.id\n",
    "        function_name = tool.function.name\n",
    "        function_args = tool.function.arguments\n",
    "\n",
    "        if function_name == \"tavily_search\":\n",
    "            output = tavily_search(query=json.loads(function_args)[\"query\"])\n",
    "\n",
    "        if output:\n",
    "            tool_output_array.append({\"tool_call_id\": tool_call_id, \"output\": output})\n",
    "\n",
    "    return client.beta.threads.runs.submit_tool_outputs(\n",
    "        thread_id=thread_id,\n",
    "        run_id=run_id,\n",
    "        tool_outputs=tool_output_array\n",
    "    )\n",
    "\n",
    "# Function to print messages from a thread\n",
    "def print_messages_from_thread(thread_id):\n",
    "    messages = client.beta.threads.messages.list(thread_id=thread_id)\n",
    "    for msg in messages:\n",
    "        print(f\"{msg.role}: {msg.content[0].text.value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are a principal software engineer with extremely in-depth experience with many different kinds of technologies. You are also highly experienced in teaching these concepts to junior developers.\n",
      "\n",
      "You are a part of a team, trying to curate learning materials for junior developers trying to learn a new technology. The entire learning material follows the format:\n",
      "\n",
      "\"# <Technology Name>\n",
      "\n",
      "## Onboarding\n",
      "\n",
      "### What problem does this aim to solve?\n",
      "\n",
      "### What sub-category of technologies is this?\n",
      "\n",
      "## Developer life with/without this tool\n",
      "\n",
      "## Core Concepts\n",
      "\n",
      "## Core APIs\n",
      "\n",
      "## Small Running Example\"\n",
      "\n",
      "We are writing in this format because this is the most effective way for junior developers to learn new technologies, and through it all the language needs to stay as grounded and specific as possible. Be detailed without being wordy.\n",
      "\n",
      "You are responsible for the \"Real Life Examples\" section. Here is some more information about what this section should include:\n",
      "\n",
      "Purpose: Present actual projects or applications that effectively implement the technology, enriching their understanding through practical examples.\n",
      "Selecting Examples: Choose 2-3 notable real-world projects or applications, ideally from platforms like GitHub.\n",
      "Brief Descriptions: Provide concise descriptions of each example, focusing on the specific use of the technology.\n",
      "Direct Links: Include links to the projects or applications for direct access and exploration.\n",
      "\n",
      "Your goal is to provide answers based on information from the internet, and they should be from www.github.com. \n",
      "You must use the provided Tavily search API function to find relevant online information. \n",
      "You should never use your own knowledge to answer questions.\n",
      "\n",
      "Example:\n",
      "\n",
      "INPUT: Docker\n",
      "\n",
      "RESPONSE:\n",
      "## Real Life Examples\n",
      "\n",
      "### Example Voting App:\n",
      "\n",
      "- Description: A distributed application demonstrating Docker's multi-container management capabilities, integrating Docker Compose, Swarm, and Kubernetes.\n",
      "- URL: https://github.com/dockersamples/example-voting-app\n",
      "\n",
      "### Wordsmith:\n",
      "\n",
      "- Description: Showcases Docker containers under Kubernetes, highlighting container orchestration.\n",
      "- URL: https://github.com/dockersamples/wordsmith\n",
      "\n",
      "### Compose-Dev-Env:\n",
      "\n",
      "- Description: Illustrates Docker's use in development environments, focusing on compose applications.\n",
      "- URL: https://github.com/dockersamples/compose-dev-env\n"
     ]
    }
   ],
   "source": [
    "print(assistant_prompt_instruction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant ID: asst_DHYLkIhXkhjIXnDnazme1MSA\n"
     ]
    }
   ],
   "source": [
    "# Create an assistant\n",
    "assistant = client.beta.assistants.create(\n",
    "    instructions=assistant_prompt_instruction,\n",
    "    model=\"gpt-4-1106-preview\",\n",
    "    tools=[{\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"tavily_search\",\n",
    "            \"description\": \"Get information on recent events from the web.\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"query\": {\"type\": \"string\", \"description\": \"The search query to use. For example: 'Simple example projects that use Docker.'\"},\n",
    "                },\n",
    "                \"required\": [\"query\"]\n",
    "            }\n",
    "        }\n",
    "    }]\n",
    ")\n",
    "assistant_id = assistant.id\n",
    "print(f\"Assistant ID: {assistant_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thread: Thread(id='thread_pMtHwEdJMsE5oBzSHnLlMJCG', created_at=1703859310, metadata={}, object='thread')\n"
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "thread = client.beta.threads.create()\n",
    "print(f\"Thread: {thread}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Ongoing conversation loop\n",
    "# while True:\n",
    "#     user_input = input(\"You: \")\n",
    "#     if user_input.lower() == 'exit':\n",
    "#         break\n",
    "\n",
    "#     # Create a message\n",
    "#     message = client.beta.threads.messages.create(\n",
    "#         thread_id=thread.id,\n",
    "#         role=\"user\",\n",
    "#         content=user_input,\n",
    "#     )\n",
    "\n",
    "#     # Create a run\n",
    "#     run = client.beta.threads.runs.create(\n",
    "#         thread_id=thread.id,\n",
    "#         assistant_id=assistant_id,\n",
    "#     )\n",
    "#     print(f\"Run ID: {run.id}\")\n",
    "\n",
    "#     # Wait for run to complete\n",
    "#     run = wait_for_run_completion(thread.id, run.id)\n",
    "\n",
    "#     if run.status == 'failed':\n",
    "#         print(run.error)\n",
    "#         continue\n",
    "#     elif run.status == 'requires_action':\n",
    "#         run = submit_tool_outputs(thread.id, run.id, run.required_action.submit_tool_outputs.tool_calls)\n",
    "#         run = wait_for_run_completion(thread.id, run.id)\n",
    "\n",
    "#     # Print messages from the thread\n",
    "#     print_messages_from_thread(thread.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a message\n",
    "technology_name = \"Kubernetes\"\n",
    "\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=technology_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run ID: run_to5EPAIOyvLgGkKEnztfy3D9\n"
     ]
    }
   ],
   "source": [
    "# Create a run\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id=thread.id,\n",
    "    assistant_id=assistant_id,\n",
    ")\n",
    "print(f\"Run ID: {run.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current run status: in_progress\n",
      "Current run status: requires_action\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: completed\n",
      "assistant: ## Real Life Examples\n",
      "\n",
      "### Docker Web Framework Examples:\n",
      "\n",
      "- Description: A collection of example applications showcasing how to use Docker with different web frameworks, providing a practical guide to containerized development.\n",
      "- URL: https://github.com/nickjj/docker-web-framework-examples\n",
      "\n",
      "### Docker Swarm Visualizer:\n",
      "\n",
      "- Description: An interactive visualization tool for Docker Swarm Mode, demonstrating the clustering and orchestration capabilities of Docker using a web-based UI.\n",
      "- URL: https://github.com/dockersamples/docker-swarm-visualizer\n",
      "\n",
      "### Docker Multi-Stage App:\n",
      "\n",
      "- Description: This example project showcases the multi-build feature of Docker, demonstrating how to optimize Dockerfiles for multi-stage builds.\n",
      "- URL: https://github.com/stackriot-labs/docker-multi-stage-app\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Wait for run to complete\n",
    "run = wait_for_run_completion(thread.id, run.id)\n",
    "\n",
    "if run.status == 'failed':\n",
    "    print(run.error)\n",
    "    exit\n",
    "elif run.status == 'requires_action':\n",
    "    run = submit_tool_outputs(thread.id, run.id, run.required_action.submit_tool_outputs.tool_calls)\n",
    "    run = wait_for_run_completion(thread.id, run.id)\n",
    "\n",
    "# Print messages from the thread\n",
    "print_messages_from_thread(thread.id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: in_progress\n",
      "Current run status: completed\n",
      "assistant: ## Real Life Examples\n",
      "\n",
      "### Airbnb:\n",
      "\n",
      "- Description: Airbnb uses Kubernetes to run the hundreds of services required to operate on a unified and scalable infrastructure.\n",
      "- URL: [Airbnb and Kubernetes](https://www.airplane.dev/blog/companies-using-kubernetes)\n",
      "\n",
      "### Amadeus:\n",
      "\n",
      "- Description: Amadeus, the travel technology company, put Kubernetes into production to improve scalability and efficiency in their operations.\n",
      "- URL: [Amadeus Kubernetes Success Story](https://www.infoworld.com/article/3455244/kubernetes-meets-the-real-world-3-success-stories.html)\n",
      "\n",
      "### Tinder:\n",
      "\n",
      "- Description: Tinder migrated to Kubernetes to handle their growing scale, helping manage the operations of their popular dating app.\n",
      "- URL: [Tinder's Migration to Kubernetes](https://dzone.com/articles/how-big-companies-are-using-kubernetes)\n",
      "\n",
      "Note: The provided URLs direct you to articles or blog posts that discuss these companies' use of Kubernetes in more detail. For full access to code or specific implementations, it's recommended to search for potential repositories on GitHub or similar platforms maintained by these organizations.\n",
      "user: Kubernetes\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flash-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
