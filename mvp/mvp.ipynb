{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from src.utils import load_prompt\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "load_dotenv(\"src/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils\n",
    "def load_text(path):\n",
    "    with open(path, \"r\") as fp:\n",
    "        return fp.read()\n",
    "\n",
    "def load_prompt(prompt):\n",
    "    return load_text(f\"prompts/{prompt}.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = ChatOpenAI(temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "core_concepts_prompt = load_prompt(\"onboarding\")\n",
    "human_prompt_template = \"{technology_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message_prompt = SystemMessagePromptTemplate.from_template(core_concepts_prompt)\n",
    "human_message_prompt = HumanMessagePromptTemplate.from_template(human_prompt_template)\n",
    "\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_message_prompt, human_message_prompt]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat(\n",
    "    chat_prompt.format_prompt(\n",
    "        technology_name=\"Apache Beam\"\n",
    "    ).to_messages()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Onboarding\n",
      "\n",
      "### What problem does this aim to solve?\n",
      "\n",
      "Apache Beam addresses the challenge of building and executing data processing pipelines that are scalable, portable, and expressive. In the world of big data, processing large volumes of data efficiently and reliably is a complex task. Traditional approaches often involve writing custom code for each data processing job, leading to code duplication, maintenance challenges, and limited scalability. Apache Beam solves these problems by providing a unified programming model and a set of APIs that enable developers to write data processing pipelines that can run on various execution engines, such as Apache Flink, Apache Spark, and Google Cloud Dataflow.\n",
      "\n",
      "### What sub-category of technologies is this?\n",
      "\n",
      "Apache Beam falls under the sub-category of \"data processing frameworks\" within the broader field of big data and distributed computing. It is a tool that simplifies the development and execution of data processing pipelines, allowing developers to focus on the logic of their data transformations rather than the underlying infrastructure. Apache Beam's portable and expressive nature makes it suitable for a wide range of use cases, including batch and stream processing, ETL (Extract, Transform, Load) pipelines, and real-time analytics.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Onboarding\n",
       "\n",
       "### What problem does this aim to solve?\n",
       "\n",
       "Apache Beam addresses the challenge of building and executing data processing pipelines that are scalable, portable, and expressive. In the world of big data, processing large volumes of data efficiently and reliably is a complex task. Traditional approaches often involve writing custom code for each data processing job, leading to code duplication, maintenance challenges, and limited scalability. Apache Beam solves these problems by providing a unified programming model and a set of APIs that enable developers to write data processing pipelines that can run on various execution engines, such as Apache Flink, Apache Spark, and Google Cloud Dataflow.\n",
       "\n",
       "### What sub-category of technologies is this?\n",
       "\n",
       "Apache Beam falls under the sub-category of \"data processing frameworks\" within the broader field of big data and distributed computing. It is a tool that simplifies the development and execution of data processing pipelines, allowing developers to focus on the logic of their data transformations rather than the underlying infrastructure. Apache Beam's portable and expressive nature makes it suitable for a wide range of use cases, including batch and stream processing, ETL (Extract, Transform, Load) pipelines, and real-time analytics."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown, Latex\n",
    "display(Markdown(response.content))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flash-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
